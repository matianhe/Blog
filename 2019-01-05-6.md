---
title: Python爬取代理IP，并存入数据库
date: 2019-01-05 17:28
id: 52368
---

> 这篇文章主要内容是对西刺网站上的免费IP进行爬取和验证，来保证对其他项目的需求。
-  目标网址：http://www.xicidaili.com/nn/  
通过查看元素，ip地址、端口、类型都可以在一个tr里找到。
![目标网站](http://upload-images.jianshu.io/upload_images/7080951-9df9a4d6cb2911f8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)  
- 爬取ip，端口，协议三个信息，并放入队列，等待检查加入数据库。

```python
def get_info(self, q):
    page = 1
    while True:
        url = 'http://www.xicidaili.com/nn/%d' % (page)
        req = requests.get(url, headers=self.header)
        soup = BeautifulSoup(req.text, 'lxml')
        trs = soup.find('table', id='ip_list').find_all('tr')
        for tr in trs[1:]:
            ip = tr.contents[3].text
            port = tr.contents[5].text
            procotol = tr.contents[11].text
            q.put((ip, port, procotol.lower()))
        page += 1

```  
- 从队列中取出信息，并用它访问一个网站，如果成功把它存到数据库中为可用IP。
```python
def check(self, q, lock):
    while True:
        data = q.get()
        try:
            req = requests.get('http://www.baidu.com',
                               proxies={'%s' % (data[2]): '%s://%s:%s'
                                         % (data[2], data[0], data[1])},
                               timeout=2, headers=self.header,
                               cookies=self.cookie)
            if req.status_code == 200:
                print(data)
                tools.i_ip(data)
            else:
                print('not200', data)
        except Exception as e:
            print(e, 'erro', data)
            pass
```

>GitHub开源地址：https://github.com/matianhe/crawler